2022-11-12 13:08:44,008 INFO    MainThread:2646601 [wandb_setup.py:_flush():68] Configure stats pid to 2646601
2022-11-12 13:08:44,008 INFO    MainThread:2646601 [wandb_setup.py:_flush():68] Loading settings from /home/zihan/.config/wandb/settings
2022-11-12 13:08:44,008 INFO    MainThread:2646601 [wandb_setup.py:_flush():68] Loading settings from /home/zihan/research/TCDM/outputs/2022-11-12/13-08-42/wandb/settings
2022-11-12 13:08:44,008 INFO    MainThread:2646601 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2022-11-12 13:08:44,008 WARNING MainThread:2646601 [wandb_setup.py:_flush():68] Could not find program at train.py
2022-11-12 13:08:44,009 INFO    MainThread:2646601 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': None, 'program': 'train.py'}
2022-11-12 13:08:44,009 INFO    MainThread:2646601 [wandb_init.py:_log_setup():476] Logging user logs to /home/zihan/research/TCDM/outputs/2022-11-12/13-08-42/wandb/run-20221112_130844-22sj3tjf/logs/debug.log
2022-11-12 13:08:44,009 INFO    MainThread:2646601 [wandb_init.py:_log_setup():477] Logging internal logs to /home/zihan/research/TCDM/outputs/2022-11-12/13-08-42/wandb/run-20221112_130844-22sj3tjf/logs/debug-internal.log
2022-11-12 13:08:44,009 INFO    MainThread:2646601 [wandb_init.py:init():516] calling init triggers
2022-11-12 13:08:44,010 INFO    MainThread:2646601 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {'agent': {'name': 'PPO', 'multi_proc': True, 'params': {'gamma': 0.95, 'gae_lambda': 0.95, 'learning_rate': 1e-05, 'ent_coef': 0.001, 'vf_coef': 0.5, 'clip_range': 0.2, 'n_steps': 4096, 'batch_size': 256, 'n_epochs': 5, 'warm_start_mean': True}, 'policy_kwargs': {'net_arch': [{'pi': [512, 256, 128], 'vf': [512, 256, 128]}], 'log_std_init': -1.6}}, 'env': {'name': 'mug-drink3', 'task_kwargs': {'append_time': True, 'pregrasp': 'motion_planned', 'reward_kwargs': {'obj_err_scale': 50, 'object_reward_scale': 10.0, 'lift_bonus_thresh': 0.02, 'lift_bonus_mag': 2.5, 'obj_com_term': 0.25, 'n_envs': '${n_envs}', 'obj_reward_ramp': 0, 'obj_reward_start': 0}}, 'env_kwargs': {}, 'info_keywords': ['obj_err', 'obj_success', 'step_obj_err', 'time_frac', 'obj_err_scale'], 'state_keyword': 'state', 'n_envs': '${n_envs}', 'vid_freq': '${vid_freq}', 'vid_length': 100}, 'exp_name': 'MimicTrainer', 'id': '${hydra.job.id}', 'resume_model': None, 'total_timesteps': 50000000, 'n_envs': 64, 'n_eval_envs': 5, 'eval_freq': 1000000, 'vid_freq': None, 'save_freq': 10000000, 'restore_checkpoint_freq': 500000, 'seed': 0, 'checkpoints': {'save_freq': 4000000, 'save_path': './models/', 'name_prefix': 'rl_model'}, 'wandb': {'project': 'PGDM', 'run_name': '${env.name}_${now:%Y-%m-%d}', 'sweep_name_prefix': 'run'}, 'defaults': {'agent': 'ppo', 'env': 'pgdm'}}
2022-11-12 13:08:44,010 INFO    MainThread:2646601 [wandb_init.py:init():569] starting backend
2022-11-12 13:08:44,010 INFO    MainThread:2646601 [wandb_init.py:init():573] setting up manager
2022-11-12 13:08:44,019 INFO    MainThread:2646601 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2022-11-12 13:08:44,031 INFO    MainThread:2646601 [wandb_init.py:init():580] backend started and connected
2022-11-12 13:08:44,039 INFO    MainThread:2646601 [wandb_init.py:init():658] updated telemetry
2022-11-12 13:08:44,094 INFO    MainThread:2646601 [wandb_init.py:init():693] communicating run to backend with 60 second timeout
2022-11-12 13:08:44,327 INFO    MainThread:2646601 [wandb_run.py:_on_init():2000] communicating current version
2022-11-12 13:08:44,395 INFO    MainThread:2646601 [wandb_run.py:_on_init():2004] got version response upgrade_message: "wandb version 0.13.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2022-11-12 13:08:44,396 INFO    MainThread:2646601 [wandb_init.py:init():728] starting run threads in backend
2022-11-12 13:08:49,433 INFO    MainThread:2646601 [wandb_run.py:_console_start():1980] atexit reg
2022-11-12 13:08:49,434 INFO    MainThread:2646601 [wandb_run.py:_redirect():1838] redirect: SettingsConsole.WRAP_RAW
2022-11-12 13:08:49,435 INFO    MainThread:2646601 [wandb_run.py:_redirect():1903] Wrapping output streams.
2022-11-12 13:08:49,435 INFO    MainThread:2646601 [wandb_run.py:_redirect():1925] Redirects installed.
2022-11-12 13:08:49,436 INFO    MainThread:2646601 [wandb_init.py:init():765] run started, returning control to user process
2022-11-12 13:09:29,185 INFO    MainThread:2646601 [wandb_run.py:_tensorboard_callback():1296] tensorboard callback: logs/PPO_1, True
2022-11-12 13:09:29,211 INFO    MainThread:2646601 [wandb_run.py:_config_callback():1160] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'tcdm.rl.models.policies.ActorCriticPolicy'>", 'device': 'cuda', '_vec_normalize_env': 'None', 'verbose': 1, 'policy_kwargs': "{'net_arch': [{'pi': [512, 256, 128], 'vf': [512, 256, 128]}], 'log_std_init': -1.6}", 'observation_space': 'Box(-inf, inf, (322,), float32)', 'action_space': 'Box(-1.0, 1.0, (30,), float32)', 'num_timesteps': 0, '_total_timesteps': 50000000, 'eval_env': 'None', 'action_noise': 'None', 'start_time': 1668276569.1094859, 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n      (0): Linear(in_features=322, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=256, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=256, out_features=128, bias=True)\n      (5): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=322, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=256, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=256, out_features=128, bias=True)\n      (5): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=128, out_features=30, bias=True)\n  (value_net): Linear(in_features=128, out_features=1, bias=True)\n)', 'learning_rate': 1e-05, 'tensorboard_log': 'logs/', 'lr_schedule': '<function constant_fn.<locals>.func at 0x7f74dac0b5e0>', '_last_obs': '[[-0.12036688 -0.15354688  0.17400995 ...  1.          1.\n   1.        ]\n [-0.12036688 -0.15354688  0.17400995 ...  1.          1.\n   1.        ]\n [-0.12036688 -0.15354688  0.17400995 ...  1.          1.\n   1.        ]\n ...\n [-0.12036688 -0.15354688  0.17400995 ...  1.          1.\n   1.        ]\n [-0.12036688 -0.15354688  0.17400995 ...  1.          1.\n   1.        ]\n [-0.12036688 -0.15354688  0.17400995 ...  1.          1.\n   1.        ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_logger': '<stable_baselines3.common.logger.Logger object at 0x7f73091f1730>', '_custom_logger': 'False', 'n_steps': 64, 'gamma': 0.95, 'gae_lambda': 0.95, 'ent_coef': 0.001, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x7f730b19a040>', 'batch_size': 256, 'n_epochs': 5, 'clip_range': '<function constant_fn.<locals>.func at 0x7f74dac49550>', 'clip_range_vf': 'None', 'target_kl': 'None'}
